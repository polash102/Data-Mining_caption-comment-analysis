{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOo47nHMQjtM7ugLCOf0CNw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polash102/Data-Mining_caption-comment-analysis/blob/main/Lab_2_477.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jZUoL9BBRIEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7606658-6732-4142-d3f6-e54ac3407b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.11/dist-packages (2025.6.30)\n",
            "fatal: destination path 'youtube-comment-downloader' already exists and is not an empty directory.\n",
            "Processing ./youtube-comment-downloader\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.11/dist-packages (from youtube-comment-downloader==0.1) (1.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-comment-downloader==0.1) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from dateparser->youtube-comment-downloader==0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser->youtube-comment-downloader==0.1) (2025.2)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from dateparser->youtube-comment-downloader==0.1) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser->youtube-comment-downloader==0.1) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-comment-downloader==0.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-comment-downloader==0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-comment-downloader==0.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-comment-downloader==0.1) (2025.7.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->dateparser->youtube-comment-downloader==0.1) (1.17.0)\n",
            "Building wheels for collected packages: youtube-comment-downloader\n",
            "  Building wheel for youtube-comment-downloader (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for youtube-comment-downloader: filename=youtube_comment_downloader-0.1-py3-none-any.whl size=8211 sha256=41e3e8084392e672d0b89f0c9be744f812def3929fdcad7d14378e2713a1329e\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/ff/30/9f7845d5d5e4ae1465d1898d3e95377e4119a41fe7a189f0c1\n",
            "Successfully built youtube-comment-downloader\n",
            "Installing collected packages: youtube-comment-downloader\n",
            "  Attempting uninstall: youtube-comment-downloader\n",
            "    Found existing installation: youtube-comment-downloader 0.1\n",
            "    Uninstalling youtube-comment-downloader-0.1:\n",
            "      Successfully uninstalled youtube-comment-downloader-0.1\n",
            "Successfully installed youtube-comment-downloader-0.1\n",
            "Requirement already satisfied: webvtt-py in /usr/local/lib/python3.11/dist-packages (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "# STEP 1: Install Required Tools\n",
        "# ===============================\n",
        "!pip install -U yt-dlp\n",
        "!git clone https://github.com/egbertbouman/youtube-comment-downloader.git\n",
        "!pip install ./youtube-comment-downloader\n",
        "!pip install webvtt-py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 2: Import Libraries\n",
        "# ===============================\n",
        "import os\n",
        "import subprocess\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import webvtt\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "PEY-dewvCsnZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 3: Define Functions\n",
        "# ===============================\n",
        "def download_captions(url, output_filename):\n",
        "    try:\n",
        "        temp_filename = \"temp_captions.vtt\"\n",
        "        command = [\n",
        "            'python3', '-m', 'yt_dlp',\n",
        "            '--write-auto-sub',\n",
        "            '--sub-lang', 'en',\n",
        "            '--skip-download',\n",
        "            '-o', temp_filename,\n",
        "            url\n",
        "        ]\n",
        "        subprocess.run(command, check=True)\n",
        "\n",
        "        # Find the actual downloaded file (yt-dlp might append to the filename)\n",
        "        downloaded_files = [f for f in os.listdir('.') if f.startswith(temp_filename.split('.')[0]) and f.endswith('.vtt')]\n",
        "        if downloaded_files:\n",
        "            actual_downloaded_file = downloaded_files[0]\n",
        "            os.rename(actual_downloaded_file, output_filename)\n",
        "            print(f\"✅ Captions downloaded and renamed to '{output_filename}'\")\n",
        "        else:\n",
        "            print(f\"❌ Error: Could not find downloaded caption file for {url}\")\n",
        "\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "\n",
        "def download_comments(url, output_filename, limit=200):\n",
        "    try:\n",
        "        command = [\n",
        "            'python3', '-m', 'youtube_comment_downloader',\n",
        "            '--url', url,\n",
        "            '--output', output_filename,\n",
        "            '--limit', str(limit)\n",
        "        ]\n",
        "        print(f\"Running command: {' '.join(command)}\")\n",
        "        result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
        "        print(\"Command stdout:\")\n",
        "        print(result.stdout)\n",
        "        print(\"Command stderr:\")\n",
        "        print(result.stderr)\n",
        "        print(f\"✅ Comments downloaded to '{output_filename}'\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        print(\"Command stdout:\")\n",
        "        print(e.stdout)\n",
        "        print(\"Command stderr:\")\n",
        "        print(e.stderr)\n",
        "\n",
        "\n",
        "def clean_vtt_file(vtt_input, txt_output=\"captions_cleaned.txt\"):\n",
        "    lines = []\n",
        "    with open(vtt_input, \"r\", encoding=\"utf-8\") as file:\n",
        "        for line in file:\n",
        "            if \"-->\" in line or line.strip() == \"\" or line.strip().isdigit():\n",
        "                continue\n",
        "            lines.append(line.strip())\n",
        "    with open(txt_output, \"w\", encoding=\"utf-8\") as out:\n",
        "        out.write(\" \".join(lines))\n",
        "    print(f\"✅ Cleaned VTT saved to '{txt_output}'\")\n",
        "\n",
        "def parse_comments_jsonl(filepath='comments.json'):\n",
        "    comments = []\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"⚠️ Comment file not found at '{filepath}'\")\n",
        "        return pd.DataFrame(comments)\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                try:\n",
        "                    comment = json.loads(line)\n",
        "                    comments.append({\n",
        "                        'username': comment.get('author', '').lstrip('@'),\n",
        "                        'timestamp_text': comment.get('time', ''),\n",
        "                        'comment_text': comment.get('text', '')\n",
        "                    })\n",
        "                except json.JSONDecodeError:\n",
        "                    print(f\"⚠️ Skipping invalid JSON line in {filepath}: {line.strip()}\")\n",
        "    if not comments:\n",
        "        print(f\"⚠️ No valid comments found in '{filepath}'\")\n",
        "    return pd.DataFrame(comments)\n",
        "\n",
        "def parse_captions_vtt(filepath='captions.vtt'):\n",
        "    try:\n",
        "        captions = [caption.text.strip() for caption in webvtt.read(filepath)]\n",
        "    except:\n",
        "        captions = []\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if '-->' not in line and line and not line.isdigit() and 'WEBVTT' not in line:\n",
        "                    captions.append(line)\n",
        "    full_text = ' '.join(captions)\n",
        "    sentences = re.split(r'(?<=[.!?]) +', full_text)\n",
        "    return pd.DataFrame(sentences, columns=['caption_sentence'])\n",
        "\n",
        "# Text cleaning pipeline\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in stop_words and len(word) > 2]\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "def clean_text_pipeline(text):\n",
        "    return lemmatize_tokens(remove_stopwords(tokenize_text(normalize_text(text))))"
      ],
      "metadata": {
        "id": "Ma9jPeMJC0wJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STEP 4: Define YouTube URLs\n",
        "# ===============================\n",
        "video_urls = [\n",
        "    \"https://www.youtube.com/watch?v=5GeAORj0Nw0\",\n",
        "    \"https://www.youtube.com/watch?v=rmASLb_Yn5Y\",\n",
        "    \"https://www.youtube.com/watch?v=jNhQoYt2dsw\",\n",
        "    \"https://www.youtube.com/watch?v=GDSf2h9_39I\",\n",
        "    \"https://www.youtube.com/watch?v=wuVVclLcjuA\",\n",
        "    \"https://www.youtube.com/watch?v=fs8ZveNZQ8g\",\n",
        "    \"https://www.youtube.com/watch?v=rjXZzB5bUAo\"\n",
        "]\n",
        "\n",
        "# ===============================\n",
        "# STEP 5: Process All 7 Videos\n",
        "# ===============================\n",
        "for i, url in enumerate(video_urls, 1):\n",
        "    print(f\"\\n====== Processing Video {i} ======\\n\")\n",
        "\n",
        "    caption_filename = f\"captions_{i}.vtt\"\n",
        "    comment_filename = f\"comments_{i}.json\"\n",
        "\n",
        "    download_captions(url, caption_filename)\n",
        "    download_comments(url, comment_filename)\n",
        "\n",
        "    # Clean captions if the file exists\n",
        "    if os.path.exists(caption_filename):\n",
        "        clean_vtt_file(caption_filename, f\"captions_cleaned_{i}.txt\")\n",
        "        # Parse and clean captions\n",
        "        captions_df = parse_captions_vtt(caption_filename)\n",
        "        captions_df['cleaned_tokens'] = captions_df['caption_sentence'].apply(clean_text_pipeline)\n",
        "        # Save cleaned captions\n",
        "        captions_df.to_csv(f'cleaned_captions_{i}.csv', index=False)\n",
        "        print(f\"✅ Saved cleaned_captions_{i}.csv\")\n",
        "    else:\n",
        "        print(f\"⚠️ Caption file not found for video {i}, skipping caption processing.\")\n",
        "\n",
        "\n",
        "    # Parse and clean comments if the file exists and is not empty\n",
        "    comments_df = parse_comments_jsonl(comment_filename)\n",
        "    if not comments_df.empty:\n",
        "        comments_df['cleaned_tokens'] = comments_df['comment_text'].apply(clean_text_pipeline)\n",
        "        # Save cleaned comments\n",
        "        comments_df.to_csv(f'cleaned_comments_{i}.csv', index=False)\n",
        "        print(f\"✅ Saved cleaned_comments_{i}.csv\")\n",
        "    else:\n",
        "        print(f\"⚠️ No comments processed for video {i} (file not found or empty).\")\n",
        "\n",
        "\n",
        "print(\"\\n✅ All 7 videos processed and cleaned successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q-4OuP5DAiH",
        "outputId": "c628b728-5a82-4524-d82d-6e856ebf1ea4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== Processing Video 1 ======\n",
            "\n",
            "✅ Captions downloaded and renamed to 'captions_1.vtt'\n",
            "Running command: python3 -m youtube_comment_downloader --url https://www.youtube.com/watch?v=5GeAORj0Nw0 --output comments_1.json --limit 200\n",
            "Command stdout:\n",
            "Downloading Youtube comments for https://www.youtube.com/watch?v=5GeAORj0Nw0\n",
            "Downloaded 1 comment(s)\n",
            "[0.84 seconds] Done!\n",
            "\n",
            "Command stderr:\n",
            "\n",
            "✅ Comments downloaded to 'comments_1.json'\n",
            "✅ Cleaned VTT saved to 'captions_cleaned_1.txt'\n",
            "✅ Saved cleaned_captions_1.csv\n",
            "⚠️ No valid comments found in 'comments_1.json'\n",
            "⚠️ No comments processed for video 1 (file not found or empty).\n",
            "\n",
            "====== Processing Video 2 ======\n",
            "\n",
            "✅ Captions downloaded and renamed to 'captions_2.vtt'\n",
            "Running command: python3 -m youtube_comment_downloader --url https://www.youtube.com/watch?v=rmASLb_Yn5Y --output comments_2.json --limit 200\n",
            "Command stdout:\n",
            "Downloading Youtube comments for https://www.youtube.com/watch?v=rmASLb_Yn5Y\n",
            "Downloaded 1 comment(s)\n",
            "Downloaded 1 comment(s)\n",
            "Downloaded 2 comment(s)\n",
            "Downloaded 3 comment(s)\n",
            "Downloaded 4 comment(s)\n",
            "Downloaded 5 comment(s)\n",
            "Downloaded 6 comment(s)\n",
            "Downloaded 7 comment(s)\n",
            "Downloaded 8 comment(s)\n",
            "Downloaded 9 comment(s)\n",
            "Downloaded 10 comment(s)\n",
            "Downloaded 11 comment(s)\n",
            "Downloaded 12 comment(s)\n",
            "Downloaded 13 comment(s)\n",
            "Downloaded 14 comment(s)\n",
            "Downloaded 15 comment(s)\n",
            "Downloaded 16 comment(s)\n",
            "Downloaded 17 comment(s)\n",
            "Downloaded 18 comment(s)\n",
            "Downloaded 19 comment(s)\n",
            "Downloaded 20 comment(s)\n",
            "Downloaded 21 comment(s)\n",
            "Downloaded 22 comment(s)\n",
            "Downloaded 23 comment(s)\n",
            "Downloaded 24 comment(s)\n",
            "Downloaded 25 comment(s)\n",
            "Downloaded 26 comment(s)\n",
            "Downloaded 27 comment(s)\n",
            "Downloaded 28 comment(s)\n",
            "Downloaded 29 comment(s)\n",
            "Downloaded 30 comment(s)\n",
            "Downloaded 31 comment(s)\n",
            "Downloaded 32 comment(s)\n",
            "Downloaded 33 comment(s)\n",
            "Downloaded 34 comment(s)\n",
            "Downloaded 35 comment(s)\n",
            "Downloaded 36 comment(s)\n",
            "Downloaded 37 comment(s)\n",
            "Downloaded 38 comment(s)\n",
            "Downloaded 39 comment(s)\n",
            "Downloaded 40 comment(s)\n",
            "Downloaded 41 comment(s)\n",
            "Downloaded 42 comment(s)\n",
            "Downloaded 43 comment(s)\n",
            "Downloaded 44 comment(s)\n",
            "Downloaded 45 comment(s)\n",
            "Downloaded 46 comment(s)\n",
            "Downloaded 47 comment(s)\n",
            "[3.29 seconds] Done!\n",
            "\n",
            "Command stderr:\n",
            "\n",
            "✅ Comments downloaded to 'comments_2.json'\n",
            "✅ Cleaned VTT saved to 'captions_cleaned_2.txt'\n",
            "✅ Saved cleaned_captions_2.csv\n",
            "✅ Saved cleaned_comments_2.csv\n",
            "\n",
            "====== Processing Video 3 ======\n",
            "\n",
            "✅ Captions downloaded and renamed to 'captions_3.vtt'\n",
            "Running command: python3 -m youtube_comment_downloader --url https://www.youtube.com/watch?v=jNhQoYt2dsw --output comments_3.json --limit 200\n",
            "Command stdout:\n",
            "Downloading Youtube comments for https://www.youtube.com/watch?v=jNhQoYt2dsw\n",
            "Downloaded 1 comment(s)\n",
            "Downloaded 1 comment(s)\n",
            "Downloaded 2 comment(s)\n",
            "Downloaded 3 comment(s)\n",
            "Downloaded 4 comment(s)\n",
            "Downloaded 5 comment(s)\n",
            "Downloaded 6 comment(s)\n",
            "Downloaded 7 comment(s)\n",
            "Downloaded 8 comment(s)\n",
            "Downloaded 9 comment(s)\n",
            "Downloaded 10 comment(s)\n",
            "Downloaded 11 comment(s)\n",
            "Downloaded 12 comment(s)\n",
            "Downloaded 13 comment(s)\n",
            "Downloaded 14 comment(s)\n",
            "Downloaded 15 comment(s)\n",
            "Downloaded 16 comment(s)\n",
            "Downloaded 17 comment(s)\n",
            "Downloaded 18 comment(s)\n",
            "Downloaded 19 comment(s)\n",
            "Downloaded 20 comment(s)\n",
            "Downloaded 21 comment(s)\n",
            "Downloaded 22 comment(s)\n",
            "Downloaded 23 comment(s)\n",
            "Downloaded 24 comment(s)\n",
            "Downloaded 25 comment(s)\n",
            "Downloaded 26 comment(s)\n",
            "Downloaded 27 comment(s)\n",
            "Downloaded 28 comment(s)\n",
            "Downloaded 29 comment(s)\n",
            "Downloaded 30 comment(s)\n",
            "[2.38 seconds] Done!\n",
            "\n",
            "Command stderr:\n",
            "\n",
            "✅ Comments downloaded to 'comments_3.json'\n",
            "✅ Cleaned VTT saved to 'captions_cleaned_3.txt'\n",
            "✅ Saved cleaned_captions_3.csv\n",
            "✅ Saved cleaned_comments_3.csv\n",
            "\n",
            "====== Processing Video 4 ======\n",
            "\n",
            "✅ Captions downloaded and renamed to 'captions_4.vtt'\n",
            "Running command: python3 -m youtube_comment_downloader --url https://www.youtube.com/watch?v=GDSf2h9_39I --output comments_4.json --limit 200\n",
            "Command stdout:\n",
            "Downloading Youtube comments for https://www.youtube.com/watch?v=GDSf2h9_39I\n",
            "Downloaded 1 comment(s)\n",
            "Downloaded 1 comment(s)\n",
            "Downloaded 2 comment(s)\n",
            "Downloaded 3 comment(s)\n",
            "Downloaded 4 comment(s)\n",
            "Downloaded 5 comment(s)\n",
            "Downloaded 6 comment(s)\n",
            "Downloaded 7 comment(s)\n",
            "Downloaded 8 comment(s)\n",
            "Downloaded 9 comment(s)\n",
            "Downloaded 10 comment(s)\n",
            "Downloaded 11 comment(s)\n",
            "Downloaded 12 comment(s)\n",
            "Downloaded 13 comment(s)\n",
            "Downloaded 14 comment(s)\n",
            "Downloaded 15 comment(s)\n",
            "Downloaded 16 comment(s)\n",
            "Downloaded 17 comment(s)\n",
            "Downloaded 18 comment(s)\n",
            "Downloaded 19 comment(s)\n",
            "Downloaded 20 comment(s)\n",
            "Downloaded 21 comment(s)\n",
            "Downloaded 22 comment(s)\n",
            "Downloaded 23 comment(s)\n",
            "Downloaded 24 comment(s)\n",
            "Downloaded 25 comment(s)\n",
            "Downloaded 26 comment(s)\n",
            "Downloaded 27 comment(s)\n",
            "Downloaded 28 comment(s)\n",
            "Downloaded 29 comment(s)\n",
            "Downloaded 30 comment(s)\n",
            "Downloaded 31 comment(s)\n",
            "Downloaded 32 comment(s)\n",
            "Downloaded 33 comment(s)\n",
            "Downloaded 34 comment(s)\n",
            "Downloaded 35 comment(s)\n",
            "Downloaded 36 comment(s)\n",
            "Downloaded 37 comment(s)\n",
            "Downloaded 38 comment(s)\n",
            "Downloaded 39 comment(s)\n",
            "Downloaded 40 comment(s)\n",
            "Downloaded 41 comment(s)\n",
            "Downloaded 42 comment(s)\n",
            "Downloaded 43 comment(s)\n",
            "Downloaded 44 comment(s)\n",
            "Downloaded 45 comment(s)\n",
            "Downloaded 46 comment(s)\n",
            "Downloaded 47 comment(s)\n",
            "Downloaded 48 comment(s)\n",
            "Downloaded 49 comment(s)\n",
            "Downloaded 50 comment(s)\n",
            "Downloaded 51 comment(s)\n",
            "Downloaded 52 comment(s)\n",
            "Downloaded 53 comment(s)\n",
            "Downloaded 54 comment(s)\n",
            "Downloaded 55 comment(s)\n",
            "Downloaded 56 comment(s)\n",
            "Downloaded 57 comment(s)\n",
            "Downloaded 58 comment(s)\n",
            "Downloaded 59 comment(s)\n",
            "Downloaded 60 comment(s)\n",
            "Downloaded 61 comment(s)\n",
            "Downloaded 62 comment(s)\n",
            "Downloaded 63 comment(s)\n",
            "Downloaded 64 comment(s)\n",
            "Downloaded 65 comment(s)\n",
            "Downloaded 66 comment(s)\n",
            "Downloaded 67 comment(s)\n",
            "Downloaded 68 comment(s)\n",
            "Downloaded 69 comment(s)\n",
            "Downloaded 70 comment(s)\n",
            "Downloaded 71 comment(s)\n",
            "Downloaded 72 comment(s)\n",
            "Downloaded 73 comment(s)\n",
            "Downloaded 74 comment(s)\n",
            "Downloaded 75 comment(s)\n",
            "Downloaded 76 comment(s)\n",
            "Downloaded 77 comment(s)\n",
            "Downloaded 78 comment(s)\n",
            "Downloaded 79 comment(s)\n",
            "Downloaded 80 comment(s)\n",
            "Downloaded 81 comment(s)\n",
            "Downloaded 82 comment(s)\n",
            "Downloaded 83 comment(s)\n",
            "Downloaded 84 comment(s)\n",
            "Downloaded 85 comment(s)\n",
            "Downloaded 86 comment(s)\n",
            "Downloaded 87 comment(s)\n",
            "Downloaded 88 comment(s)\n",
            "Downloaded 89 comment(s)\n",
            "Downloaded 90 comment(s)\n",
            "Downloaded 91 comment(s)\n",
            "Downloaded 92 comment(s)\n",
            "Downloaded 93 comment(s)\n",
            "Downloaded 94 comment(s)\n",
            "Downloaded 95 comment(s)\n",
            "Downloaded 96 comment(s)\n",
            "Downloaded 97 comment(s)\n",
            "Downloaded 98 comment(s)\n",
            "Downloaded 99 comment(s)\n",
            "Downloaded 100 comment(s)\n",
            "Downloaded 101 comment(s)\n",
            "Downloaded 102 comment(s)\n",
            "Downloaded 103 comment(s)\n",
            "Downloaded 104 comment(s)\n",
            "Downloaded 105 comment(s)\n",
            "Downloaded 106 comment(s)\n",
            "Downloaded 107 comment(s)\n",
            "Downloaded 108 comment(s)\n",
            "Downloaded 109 comment(s)\n",
            "Downloaded 110 comment(s)\n",
            "Downloaded 111 comment(s)\n",
            "Downloaded 112 comment(s)\n",
            "Downloaded 113 comment(s)\n",
            "Downloaded 114 comment(s)\n",
            "Downloaded 115 comment(s)\n",
            "Downloaded 116 comment(s)\n",
            "Downloaded 117 comment(s)\n",
            "Downloaded 118 comment(s)\n",
            "Downloaded 119 comment(s)\n",
            "Downloaded 120 comment(s)\n",
            "Downloaded 121 comment(s)\n",
            "Downloaded 122 comment(s)\n",
            "Downloaded 123 comment(s)\n",
            "Downloaded 124 comment(s)\n",
            "Downloaded 125 comment(s)\n",
            "Downloaded 126 comment(s)\n",
            "Downloaded 127 comment(s)\n",
            "Downloaded 128 comment(s)\n",
            "Downloaded 129 comment(s)\n",
            "Downloaded 130 comment(s)\n",
            "Downloaded 131 comment(s)\n",
            "Downloaded 132 comment(s)\n",
            "Downloaded 133 comment(s)\n",
            "Downloaded 134 comment(s)\n",
            "Downloaded 135 comment(s)\n",
            "Downloaded 136 comment(s)\n",
            "Downloaded 137 comment(s)\n",
            "Downloaded 138 comment(s)\n",
            "Downloaded 139 comment(s)\n",
            "Downloaded 140 comment(s)\n",
            "Downloaded 141 comment(s)\n",
            "Downloaded 142 comment(s)\n",
            "Downloaded 143 comment(s)\n",
            "Downloaded 144 comment(s)\n",
            "Downloaded 145 comment(s)\n",
            "Downloaded 146 comment(s)\n",
            "Downloaded 147 comment(s)\n",
            "Downloaded 148 comment(s)\n",
            "Downloaded 149 comment(s)\n",
            "Downloaded 150 comment(s)\n",
            "Downloaded 151 comment(s)\n",
            "Downloaded 152 comment(s)\n",
            "Downloaded 153 comment(s)\n",
            "Downloaded 154 comment(s)\n",
            "Downloaded 155 comment(s)\n",
            "Downloaded 156 comment(s)\n",
            "Downloaded 157 comment(s)\n",
            "Downloaded 158 comment(s)\n",
            "Downloaded 159 comment(s)\n",
            "Downloaded 160 comment(s)\n",
            "Downloaded 161 comment(s)\n",
            "Downloaded 162 comment(s)\n",
            "Downloaded 163 comment(s)\n",
            "Downloaded 164 comment(s)\n",
            "Downloaded 165 comment(s)\n",
            "Downloaded 166 comment(s)\n",
            "Downloaded 167 comment(s)\n",
            "Downloaded 168 comment(s)\n",
            "Downloaded 169 comment(s)\n",
            "Downloaded 170 comment(s)\n",
            "Downloaded 171 comment(s)\n",
            "Downloaded 172 comment(s)\n",
            "Downloaded 173 comment(s)\n",
            "Downloaded 174 comment(s)\n",
            "Downloaded 175 comment(s)\n",
            "Downloaded 176 comment(s)\n",
            "Downloaded 177 comment(s)\n",
            "Downloaded 178 comment(s)\n",
            "Downloaded 179 comment(s)\n",
            "Downloaded 180 comment(s)\n",
            "Downloaded 181 comment(s)\n",
            "Downloaded 182 comment(s)\n",
            "Downloaded 183 comment(s)\n",
            "Downloaded 184 comment(s)\n",
            "Downloaded 185 comment(s)\n",
            "Downloaded 186 comment(s)\n",
            "Downloaded 187 comment(s)\n",
            "Downloaded 188 comment(s)\n",
            "Downloaded 189 comment(s)\n",
            "Downloaded 190 comment(s)\n",
            "Downloaded 191 comment(s)\n",
            "Downloaded 192 comment(s)\n",
            "Downloaded 193 comment(s)\n",
            "Downloaded 194 comment(s)\n",
            "Downloaded 195 comment(s)\n",
            "Downloaded 196 comment(s)\n",
            "Downloaded 197 comment(s)\n",
            "Downloaded 198 comment(s)\n",
            "Downloaded 199 comment(s)\n",
            "Downloaded 200 comment(s)\n",
            "[3.90 seconds] Done!\n",
            "\n",
            "Command stderr:\n",
            "\n",
            "✅ Comments downloaded to 'comments_4.json'\n",
            "✅ Cleaned VTT saved to 'captions_cleaned_4.txt'\n",
            "✅ Saved cleaned_captions_4.csv\n",
            "✅ Saved cleaned_comments_4.csv\n",
            "\n",
            "====== Processing Video 5 ======\n",
            "\n",
            "✅ Captions downloaded and renamed to 'captions_5.vtt'\n",
            "Running command: python3 -m youtube_comment_downloader --url https://www.youtube.com/watch?v=wuVVclLcjuA --output comments_5.json --limit 200\n",
            "Command stdout:\n",
            "Downloading Youtube comments for https://www.youtube.com/watch?v=wuVVclLcjuA\n",
            "Downloaded 1 comment(s)\n",
            "Downloaded 1 comment(s)\n",
            "Downloaded 2 comment(s)\n",
            "Downloaded 3 comment(s)\n",
            "Downloaded 4 comment(s)\n",
            "Downloaded 5 comment(s)\n",
            "Downloaded 6 comment(s)\n",
            "Downloaded 7 comment(s)\n",
            "Downloaded 8 comment(s)\n",
            "Downloaded 9 comment(s)\n",
            "Downloaded 10 comment(s)\n",
            "Downloaded 11 comment(s)\n",
            "Downloaded 12 comment(s)\n",
            "Downloaded 13 comment(s)\n",
            "Downloaded 14 comment(s)\n",
            "Downloaded 15 comment(s)\n",
            "Downloaded 16 comment(s)\n",
            "Downloaded 17 comment(s)\n",
            "Downloaded 18 comment(s)\n",
            "Downloaded 19 comment(s)\n",
            "Downloaded 20 comment(s)\n",
            "Downloaded 21 comment(s)\n",
            "Downloaded 22 comment(s)\n",
            "Downloaded 23 comment(s)\n",
            "Downloaded 24 comment(s)\n",
            "Downloaded 25 comment(s)\n",
            "Downloaded 26 comment(s)\n",
            "Downloaded 27 comment(s)\n",
            "Downloaded 28 comment(s)\n",
            "Downloaded 29 comment(s)\n",
            "Downloaded 30 comment(s)\n",
            "Downloaded 31 comment(s)\n",
            "Downloaded 32 comment(s)\n",
            "Downloaded 33 comment(s)\n",
            "Downloaded 34 comment(s)\n",
            "Downloaded 35 comment(s)\n",
            "Downloaded 36 comment(s)\n",
            "Downloaded 37 comment(s)\n",
            "Downloaded 38 comment(s)\n",
            "Downloaded 39 comment(s)\n",
            "Downloaded 40 comment(s)\n",
            "Downloaded 41 comment(s)\n",
            "Downloaded 42 comment(s)\n",
            "Downloaded 43 comment(s)\n",
            "Downloaded 44 comment(s)\n",
            "Downloaded 45 comment(s)\n",
            "Downloaded 46 comment(s)\n",
            "Downloaded 47 comment(s)\n",
            "Downloaded 48 comment(s)\n",
            "Downloaded 49 comment(s)\n",
            "Downloaded 50 comment(s)\n",
            "Downloaded 51 comment(s)\n",
            "Downloaded 52 comment(s)\n",
            "Downloaded 53 comment(s)\n",
            "Downloaded 54 comment(s)\n",
            "Downloaded 55 comment(s)\n",
            "Downloaded 56 comment(s)\n",
            "Downloaded 57 comment(s)\n",
            "Downloaded 58 comment(s)\n",
            "Downloaded 59 comment(s)\n",
            "Downloaded 60 comment(s)\n",
            "Downloaded 61 comment(s)\n",
            "Downloaded 62 comment(s)\n",
            "Downloaded 63 comment(s)\n",
            "Downloaded 64 comment(s)\n",
            "Downloaded 65 comment(s)\n",
            "Downloaded 66 comment(s)\n",
            "Downloaded 67 comment(s)\n",
            "Downloaded 68 comment(s)\n",
            "Downloaded 69 comment(s)\n",
            "Downloaded 70 comment(s)\n",
            "Downloaded 71 comment(s)\n",
            "Downloaded 72 comment(s)\n",
            "Downloaded 73 comment(s)\n",
            "Downloaded 74 comment(s)\n",
            "Downloaded 75 comment(s)\n",
            "Downloaded 76 comment(s)\n",
            "Downloaded 77 comment(s)\n",
            "Downloaded 78 comment(s)\n",
            "Downloaded 79 comment(s)\n",
            "Downloaded 80 comment(s)\n",
            "Downloaded 81 comment(s)\n",
            "Downloaded 82 comment(s)\n",
            "Downloaded 83 comment(s)\n",
            "Downloaded 84 comment(s)\n",
            "Downloaded 85 comment(s)\n",
            "Downloaded 86 comment(s)\n",
            "Downloaded 87 comment(s)\n",
            "Downloaded 88 comment(s)\n",
            "Downloaded 89 comment(s)\n",
            "Downloaded 90 comment(s)\n",
            "Downloaded 91 comment(s)\n",
            "Downloaded 92 comment(s)\n",
            "Downloaded 93 comment(s)\n",
            "Downloaded 94 comment(s)\n",
            "Downloaded 95 comment(s)\n",
            "Downloaded 96 comment(s)\n",
            "Downloaded 97 comment(s)\n",
            "Downloaded 98 comment(s)\n",
            "Downloaded 99 comment(s)\n",
            "Downloaded 100 comment(s)\n",
            "Downloaded 101 comment(s)\n",
            "Downloaded 102 comment(s)\n",
            "Downloaded 103 comment(s)\n",
            "Downloaded 104 comment(s)\n",
            "Downloaded 105 comment(s)\n",
            "Downloaded 106 comment(s)\n",
            "Downloaded 107 comment(s)\n",
            "Downloaded 108 comment(s)\n",
            "Downloaded 109 comment(s)\n",
            "Downloaded 110 comment(s)\n",
            "Downloaded 111 comment(s)\n",
            "Downloaded 112 comment(s)\n",
            "Downloaded 113 comment(s)\n",
            "Downloaded 114 comment(s)\n",
            "Downloaded 115 comment(s)\n",
            "Downloaded 116 comment(s)\n",
            "Downloaded 117 comment(s)\n",
            "Downloaded 118 comment(s)\n",
            "Downloaded 119 comment(s)\n",
            "Downloaded 120 comment(s)\n",
            "Downloaded 121 comment(s)\n",
            "Downloaded 122 comment(s)\n",
            "Downloaded 123 comment(s)\n",
            "Downloaded 124 comment(s)\n",
            "Downloaded 125 comment(s)\n",
            "Downloaded 126 comment(s)\n",
            "Downloaded 127 comment(s)\n",
            "Downloaded 128 comment(s)\n",
            "Downloaded 129 comment(s)\n",
            "Downloaded 130 comment(s)\n",
            "Downloaded 131 comment(s)\n",
            "Downloaded 132 comment(s)\n",
            "Downloaded 133 comment(s)\n",
            "Downloaded 134 comment(s)\n",
            "Downloaded 135 comment(s)\n",
            "Downloaded 136 comment(s)\n",
            "Downloaded 137 comment(s)\n",
            "Downloaded 138 comment(s)\n",
            "Downloaded 139 comment(s)\n",
            "Downloaded 140 comment(s)\n",
            "Downloaded 141 comment(s)\n",
            "Downloaded 142 comment(s)\n",
            "Downloaded 143 comment(s)\n",
            "Downloaded 144 comment(s)\n",
            "Downloaded 145 comment(s)\n",
            "Downloaded 146 comment(s)\n",
            "Downloaded 147 comment(s)\n",
            "Downloaded 148 comment(s)\n",
            "Downloaded 149 comment(s)\n",
            "Downloaded 150 comment(s)\n",
            "Downloaded 151 comment(s)\n",
            "Downloaded 152 comment(s)\n",
            "Downloaded 153 comment(s)\n",
            "Downloaded 154 comment(s)\n",
            "[9.36 seconds] Done!\n",
            "\n",
            "Command stderr:\n",
            "\n",
            "✅ Comments downloaded to 'comments_5.json'\n",
            "✅ Cleaned VTT saved to 'captions_cleaned_5.txt'\n",
            "✅ Saved cleaned_captions_5.csv\n",
            "✅ Saved cleaned_comments_5.csv\n",
            "\n",
            "====== Processing Video 6 ======\n",
            "\n",
            "✅ Captions downloaded and renamed to 'captions_6.vtt'\n",
            "Running command: python3 -m youtube_comment_downloader --url https://www.youtube.com/watch?v=fs8ZveNZQ8g --output comments_6.json --limit 200\n",
            "Command stdout:\n",
            "Downloading Youtube comments for https://www.youtube.com/watch?v=fs8ZveNZQ8g\n",
            "Downloaded 1 comment(s)\n",
            "Downloaded 1 comment(s)\n",
            "Downloaded 2 comment(s)\n",
            "Downloaded 3 comment(s)\n",
            "Downloaded 4 comment(s)\n",
            "Downloaded 5 comment(s)\n",
            "Downloaded 6 comment(s)\n",
            "Downloaded 7 comment(s)\n",
            "Downloaded 8 comment(s)\n",
            "Downloaded 9 comment(s)\n",
            "Downloaded 10 comment(s)\n",
            "Downloaded 11 comment(s)\n",
            "Downloaded 12 comment(s)\n",
            "Downloaded 13 comment(s)\n",
            "Downloaded 14 comment(s)\n",
            "Downloaded 15 comment(s)\n",
            "Downloaded 16 comment(s)\n",
            "Downloaded 17 comment(s)\n",
            "Downloaded 18 comment(s)\n",
            "Downloaded 19 comment(s)\n",
            "Downloaded 20 comment(s)\n",
            "Downloaded 21 comment(s)\n",
            "Downloaded 22 comment(s)\n",
            "Downloaded 23 comment(s)\n",
            "Downloaded 24 comment(s)\n",
            "Downloaded 25 comment(s)\n",
            "Downloaded 26 comment(s)\n",
            "Downloaded 27 comment(s)\n",
            "Downloaded 28 comment(s)\n",
            "Downloaded 29 comment(s)\n",
            "Downloaded 30 comment(s)\n",
            "Downloaded 31 comment(s)\n",
            "Downloaded 32 comment(s)\n",
            "Downloaded 33 comment(s)\n",
            "Downloaded 34 comment(s)\n",
            "Downloaded 35 comment(s)\n",
            "Downloaded 36 comment(s)\n",
            "Downloaded 37 comment(s)\n",
            "Downloaded 38 comment(s)\n",
            "Downloaded 39 comment(s)\n",
            "Downloaded 40 comment(s)\n",
            "Downloaded 41 comment(s)\n",
            "Downloaded 42 comment(s)\n",
            "Downloaded 43 comment(s)\n",
            "Downloaded 44 comment(s)\n",
            "Downloaded 45 comment(s)\n",
            "Downloaded 46 comment(s)\n",
            "Downloaded 47 comment(s)\n",
            "Downloaded 48 comment(s)\n",
            "Downloaded 49 comment(s)\n",
            "Downloaded 50 comment(s)\n",
            "Downloaded 51 comment(s)\n",
            "Downloaded 52 comment(s)\n",
            "Downloaded 53 comment(s)\n",
            "Downloaded 54 comment(s)\n",
            "Downloaded 55 comment(s)\n",
            "Downloaded 56 comment(s)\n",
            "Downloaded 57 comment(s)\n",
            "Downloaded 58 comment(s)\n",
            "Downloaded 59 comment(s)\n",
            "Downloaded 60 comment(s)\n",
            "Downloaded 61 comment(s)\n",
            "Downloaded 62 comment(s)\n",
            "Downloaded 63 comment(s)\n",
            "Downloaded 64 comment(s)\n",
            "Downloaded 65 comment(s)\n",
            "Downloaded 66 comment(s)\n",
            "Downloaded 67 comment(s)\n",
            "Downloaded 68 comment(s)\n",
            "Downloaded 69 comment(s)\n",
            "Downloaded 70 comment(s)\n",
            "Downloaded 71 comment(s)\n",
            "Downloaded 72 comment(s)\n",
            "Downloaded 73 comment(s)\n",
            "Downloaded 74 comment(s)\n",
            "Downloaded 75 comment(s)\n",
            "Downloaded 76 comment(s)\n",
            "Downloaded 77 comment(s)\n",
            "Downloaded 78 comment(s)\n",
            "Downloaded 79 comment(s)\n",
            "Downloaded 80 comment(s)\n",
            "Downloaded 81 comment(s)\n",
            "Downloaded 82 comment(s)\n",
            "Downloaded 83 comment(s)\n",
            "Downloaded 84 comment(s)\n",
            "Downloaded 85 comment(s)\n",
            "Downloaded 86 comment(s)\n",
            "Downloaded 87 comment(s)\n",
            "Downloaded 88 comment(s)\n",
            "Downloaded 89 comment(s)\n",
            "Downloaded 90 comment(s)\n",
            "Downloaded 91 comment(s)\n",
            "Downloaded 92 comment(s)\n",
            "Downloaded 93 comment(s)\n",
            "Downloaded 94 comment(s)\n",
            "Downloaded 95 comment(s)\n",
            "Downloaded 96 comment(s)\n",
            "Downloaded 97 comment(s)\n",
            "Downloaded 98 comment(s)\n",
            "Downloaded 99 comment(s)\n",
            "Downloaded 100 comment(s)\n",
            "Downloaded 101 comment(s)\n",
            "Downloaded 102 comment(s)\n",
            "Downloaded 103 comment(s)\n",
            "Downloaded 104 comment(s)\n",
            "Downloaded 105 comment(s)\n",
            "Downloaded 106 comment(s)\n",
            "Downloaded 107 comment(s)\n",
            "Downloaded 108 comment(s)\n",
            "Downloaded 109 comment(s)\n",
            "Downloaded 110 comment(s)\n",
            "Downloaded 111 comment(s)\n",
            "Downloaded 112 comment(s)\n",
            "Downloaded 113 comment(s)\n",
            "Downloaded 114 comment(s)\n",
            "Downloaded 115 comment(s)\n",
            "Downloaded 116 comment(s)\n",
            "Downloaded 117 comment(s)\n",
            "Downloaded 118 comment(s)\n",
            "Downloaded 119 comment(s)\n",
            "Downloaded 120 comment(s)\n",
            "Downloaded 121 comment(s)\n",
            "Downloaded 122 comment(s)\n",
            "Downloaded 123 comment(s)\n",
            "Downloaded 124 comment(s)\n",
            "Downloaded 125 comment(s)\n",
            "Downloaded 126 comment(s)\n",
            "Downloaded 127 comment(s)\n",
            "Downloaded 128 comment(s)\n",
            "Downloaded 129 comment(s)\n",
            "Downloaded 130 comment(s)\n",
            "Downloaded 131 comment(s)\n",
            "Downloaded 132 comment(s)\n",
            "Downloaded 133 comment(s)\n",
            "Downloaded 134 comment(s)\n",
            "Downloaded 135 comment(s)\n",
            "Downloaded 136 comment(s)\n",
            "Downloaded 137 comment(s)\n",
            "Downloaded 138 comment(s)\n",
            "Downloaded 139 comment(s)\n",
            "Downloaded 140 comment(s)\n",
            "Downloaded 141 comment(s)\n",
            "Downloaded 142 comment(s)\n",
            "Downloaded 143 comment(s)\n",
            "Downloaded 144 comment(s)\n",
            "Downloaded 145 comment(s)\n",
            "Downloaded 146 comment(s)\n",
            "Downloaded 147 comment(s)\n",
            "Downloaded 148 comment(s)\n",
            "Downloaded 149 comment(s)\n",
            "Downloaded 150 comment(s)\n",
            "Downloaded 151 comment(s)\n",
            "Downloaded 152 comment(s)\n",
            "Downloaded 153 comment(s)\n",
            "Downloaded 154 comment(s)\n",
            "Downloaded 155 comment(s)\n",
            "Downloaded 156 comment(s)\n",
            "Downloaded 157 comment(s)\n",
            "Downloaded 158 comment(s)\n",
            "Downloaded 159 comment(s)\n",
            "Downloaded 160 comment(s)\n",
            "Downloaded 161 comment(s)\n",
            "Downloaded 162 comment(s)\n",
            "Downloaded 163 comment(s)\n",
            "Downloaded 164 comment(s)\n",
            "Downloaded 165 comment(s)\n",
            "Downloaded 166 comment(s)\n",
            "Downloaded 167 comment(s)\n",
            "Downloaded 168 comment(s)\n",
            "Downloaded 169 comment(s)\n",
            "Downloaded 170 comment(s)\n",
            "Downloaded 171 comment(s)\n",
            "Downloaded 172 comment(s)\n",
            "Downloaded 173 comment(s)\n",
            "Downloaded 174 comment(s)\n",
            "Downloaded 175 comment(s)\n",
            "Downloaded 176 comment(s)\n",
            "Downloaded 177 comment(s)\n",
            "Downloaded 178 comment(s)\n",
            "Downloaded 179 comment(s)\n",
            "Downloaded 180 comment(s)\n",
            "Downloaded 181 comment(s)\n",
            "Downloaded 182 comment(s)\n",
            "Downloaded 183 comment(s)\n",
            "Downloaded 184 comment(s)\n",
            "Downloaded 185 comment(s)\n",
            "Downloaded 186 comment(s)\n",
            "Downloaded 187 comment(s)\n",
            "Downloaded 188 comment(s)\n",
            "Downloaded 189 comment(s)\n",
            "Downloaded 190 comment(s)\n",
            "Downloaded 191 comment(s)\n",
            "Downloaded 192 comment(s)\n",
            "Downloaded 193 comment(s)\n",
            "Downloaded 194 comment(s)\n",
            "Downloaded 195 comment(s)\n",
            "Downloaded 196 comment(s)\n",
            "Downloaded 197 comment(s)\n",
            "Downloaded 198 comment(s)\n",
            "Downloaded 199 comment(s)\n",
            "Downloaded 200 comment(s)\n",
            "[6.98 seconds] Done!\n",
            "\n",
            "Command stderr:\n",
            "\n",
            "✅ Comments downloaded to 'comments_6.json'\n",
            "✅ Cleaned VTT saved to 'captions_cleaned_6.txt'\n",
            "✅ Saved cleaned_captions_6.csv\n",
            "✅ Saved cleaned_comments_6.csv\n",
            "\n",
            "====== Processing Video 7 ======\n",
            "\n",
            "✅ Captions downloaded and renamed to 'captions_7.vtt'\n",
            "Running command: python3 -m youtube_comment_downloader --url https://www.youtube.com/watch?v=rjXZzB5bUAo --output comments_7.json --limit 200\n",
            "Command stdout:\n",
            "Downloading Youtube comments for https://www.youtube.com/watch?v=rjXZzB5bUAo\n",
            "Downloaded 1 comment(s)\n",
            "Downloaded 1 comment(s)\n",
            "Downloaded 2 comment(s)\n",
            "Downloaded 3 comment(s)\n",
            "Downloaded 4 comment(s)\n",
            "Downloaded 5 comment(s)\n",
            "Downloaded 6 comment(s)\n",
            "Downloaded 7 comment(s)\n",
            "Downloaded 8 comment(s)\n",
            "Downloaded 9 comment(s)\n",
            "Downloaded 10 comment(s)\n",
            "Downloaded 11 comment(s)\n",
            "Downloaded 12 comment(s)\n",
            "Downloaded 13 comment(s)\n",
            "Downloaded 14 comment(s)\n",
            "Downloaded 15 comment(s)\n",
            "Downloaded 16 comment(s)\n",
            "Downloaded 17 comment(s)\n",
            "Downloaded 18 comment(s)\n",
            "Downloaded 19 comment(s)\n",
            "Downloaded 20 comment(s)\n",
            "Downloaded 21 comment(s)\n",
            "Downloaded 22 comment(s)\n",
            "Downloaded 23 comment(s)\n",
            "Downloaded 24 comment(s)\n",
            "Downloaded 25 comment(s)\n",
            "Downloaded 26 comment(s)\n",
            "Downloaded 27 comment(s)\n",
            "Downloaded 28 comment(s)\n",
            "Downloaded 29 comment(s)\n",
            "Downloaded 30 comment(s)\n",
            "Downloaded 31 comment(s)\n",
            "Downloaded 32 comment(s)\n",
            "Downloaded 33 comment(s)\n",
            "Downloaded 34 comment(s)\n",
            "Downloaded 35 comment(s)\n",
            "Downloaded 36 comment(s)\n",
            "Downloaded 37 comment(s)\n",
            "Downloaded 38 comment(s)\n",
            "Downloaded 39 comment(s)\n",
            "Downloaded 40 comment(s)\n",
            "Downloaded 41 comment(s)\n",
            "Downloaded 42 comment(s)\n",
            "Downloaded 43 comment(s)\n",
            "Downloaded 44 comment(s)\n",
            "Downloaded 45 comment(s)\n",
            "Downloaded 46 comment(s)\n",
            "Downloaded 47 comment(s)\n",
            "Downloaded 48 comment(s)\n",
            "Downloaded 49 comment(s)\n",
            "Downloaded 50 comment(s)\n",
            "Downloaded 51 comment(s)\n",
            "Downloaded 52 comment(s)\n",
            "Downloaded 53 comment(s)\n",
            "Downloaded 54 comment(s)\n",
            "Downloaded 55 comment(s)\n",
            "Downloaded 56 comment(s)\n",
            "Downloaded 57 comment(s)\n",
            "Downloaded 58 comment(s)\n",
            "Downloaded 59 comment(s)\n",
            "Downloaded 60 comment(s)\n",
            "Downloaded 61 comment(s)\n",
            "Downloaded 62 comment(s)\n",
            "Downloaded 63 comment(s)\n",
            "Downloaded 64 comment(s)\n",
            "Downloaded 65 comment(s)\n",
            "Downloaded 66 comment(s)\n",
            "Downloaded 67 comment(s)\n",
            "Downloaded 68 comment(s)\n",
            "Downloaded 69 comment(s)\n",
            "Downloaded 70 comment(s)\n",
            "Downloaded 71 comment(s)\n",
            "Downloaded 72 comment(s)\n",
            "Downloaded 73 comment(s)\n",
            "Downloaded 74 comment(s)\n",
            "Downloaded 75 comment(s)\n",
            "Downloaded 76 comment(s)\n",
            "Downloaded 77 comment(s)\n",
            "Downloaded 78 comment(s)\n",
            "Downloaded 79 comment(s)\n",
            "Downloaded 80 comment(s)\n",
            "Downloaded 81 comment(s)\n",
            "Downloaded 82 comment(s)\n",
            "Downloaded 83 comment(s)\n",
            "Downloaded 84 comment(s)\n",
            "Downloaded 85 comment(s)\n",
            "Downloaded 86 comment(s)\n",
            "Downloaded 87 comment(s)\n",
            "Downloaded 88 comment(s)\n",
            "Downloaded 89 comment(s)\n",
            "Downloaded 90 comment(s)\n",
            "Downloaded 91 comment(s)\n",
            "Downloaded 92 comment(s)\n",
            "Downloaded 93 comment(s)\n",
            "Downloaded 94 comment(s)\n",
            "Downloaded 95 comment(s)\n",
            "Downloaded 96 comment(s)\n",
            "Downloaded 97 comment(s)\n",
            "Downloaded 98 comment(s)\n",
            "Downloaded 99 comment(s)\n",
            "Downloaded 100 comment(s)\n",
            "Downloaded 101 comment(s)\n",
            "Downloaded 102 comment(s)\n",
            "Downloaded 103 comment(s)\n",
            "Downloaded 104 comment(s)\n",
            "Downloaded 105 comment(s)\n",
            "Downloaded 106 comment(s)\n",
            "Downloaded 107 comment(s)\n",
            "Downloaded 108 comment(s)\n",
            "Downloaded 109 comment(s)\n",
            "Downloaded 110 comment(s)\n",
            "Downloaded 111 comment(s)\n",
            "Downloaded 112 comment(s)\n",
            "Downloaded 113 comment(s)\n",
            "Downloaded 114 comment(s)\n",
            "Downloaded 115 comment(s)\n",
            "Downloaded 116 comment(s)\n",
            "Downloaded 117 comment(s)\n",
            "Downloaded 118 comment(s)\n",
            "Downloaded 119 comment(s)\n",
            "Downloaded 120 comment(s)\n",
            "Downloaded 121 comment(s)\n",
            "Downloaded 122 comment(s)\n",
            "Downloaded 123 comment(s)\n",
            "Downloaded 124 comment(s)\n",
            "Downloaded 125 comment(s)\n",
            "Downloaded 126 comment(s)\n",
            "Downloaded 127 comment(s)\n",
            "Downloaded 128 comment(s)\n",
            "Downloaded 129 comment(s)\n",
            "Downloaded 130 comment(s)\n",
            "Downloaded 131 comment(s)\n",
            "Downloaded 132 comment(s)\n",
            "Downloaded 133 comment(s)\n",
            "Downloaded 134 comment(s)\n",
            "Downloaded 135 comment(s)\n",
            "Downloaded 136 comment(s)\n",
            "Downloaded 137 comment(s)\n",
            "Downloaded 138 comment(s)\n",
            "Downloaded 139 comment(s)\n",
            "Downloaded 140 comment(s)\n",
            "Downloaded 141 comment(s)\n",
            "Downloaded 142 comment(s)\n",
            "Downloaded 143 comment(s)\n",
            "Downloaded 144 comment(s)\n",
            "Downloaded 145 comment(s)\n",
            "Downloaded 146 comment(s)\n",
            "Downloaded 147 comment(s)\n",
            "Downloaded 148 comment(s)\n",
            "Downloaded 149 comment(s)\n",
            "Downloaded 150 comment(s)\n",
            "Downloaded 151 comment(s)\n",
            "Downloaded 152 comment(s)\n",
            "Downloaded 153 comment(s)\n",
            "Downloaded 154 comment(s)\n",
            "Downloaded 155 comment(s)\n",
            "Downloaded 156 comment(s)\n",
            "Downloaded 157 comment(s)\n",
            "Downloaded 158 comment(s)\n",
            "Downloaded 159 comment(s)\n",
            "Downloaded 160 comment(s)\n",
            "Downloaded 161 comment(s)\n",
            "Downloaded 162 comment(s)\n",
            "Downloaded 163 comment(s)\n",
            "Downloaded 164 comment(s)\n",
            "Downloaded 165 comment(s)\n",
            "Downloaded 166 comment(s)\n",
            "Downloaded 167 comment(s)\n",
            "Downloaded 168 comment(s)\n",
            "Downloaded 169 comment(s)\n",
            "Downloaded 170 comment(s)\n",
            "Downloaded 171 comment(s)\n",
            "Downloaded 172 comment(s)\n",
            "Downloaded 173 comment(s)\n",
            "Downloaded 174 comment(s)\n",
            "Downloaded 175 comment(s)\n",
            "Downloaded 176 comment(s)\n",
            "Downloaded 177 comment(s)\n",
            "Downloaded 178 comment(s)\n",
            "Downloaded 179 comment(s)\n",
            "Downloaded 180 comment(s)\n",
            "Downloaded 181 comment(s)\n",
            "Downloaded 182 comment(s)\n",
            "Downloaded 183 comment(s)\n",
            "Downloaded 184 comment(s)\n",
            "Downloaded 185 comment(s)\n",
            "Downloaded 186 comment(s)\n",
            "Downloaded 187 comment(s)\n",
            "Downloaded 188 comment(s)\n",
            "Downloaded 189 comment(s)\n",
            "Downloaded 190 comment(s)\n",
            "Downloaded 191 comment(s)\n",
            "Downloaded 192 comment(s)\n",
            "Downloaded 193 comment(s)\n",
            "Downloaded 194 comment(s)\n",
            "Downloaded 195 comment(s)\n",
            "Downloaded 196 comment(s)\n",
            "Downloaded 197 comment(s)\n",
            "Downloaded 198 comment(s)\n",
            "Downloaded 199 comment(s)\n",
            "Downloaded 200 comment(s)\n",
            "[5.61 seconds] Done!\n",
            "\n",
            "Command stderr:\n",
            "\n",
            "✅ Comments downloaded to 'comments_7.json'\n",
            "✅ Cleaned VTT saved to 'captions_cleaned_7.txt'\n",
            "✅ Saved cleaned_captions_7.csv\n",
            "✅ Saved cleaned_comments_7.csv\n",
            "\n",
            "✅ All 7 videos processed and cleaned successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "228cc7e5",
        "outputId": "97a214f4-0eeb-4d53-b111-d3157605bad1"
      },
      "source": [
        "# ===============================\n",
        "# STEP 2a: Download NLTK Data\n",
        "# ===============================\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3e7a1d9"
      },
      "source": [
        "# Task\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17d413be"
      },
      "source": [
        "## Combine captions\n",
        "\n",
        "### Subtask:\n",
        "Read the cleaned caption data from the individual CSV files, combine them into a single DataFrame, and save it as a single CSV file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4438256",
        "outputId": "995849cf-d9fe-4109-b38f-73d0f5fdffea"
      },
      "source": [
        "# Create an empty list to store the DataFrames\n",
        "all_captions_dfs = []\n",
        "\n",
        "# Loop through the video numbers from 1 to 7\n",
        "for i in range(1, 8):\n",
        "    # Construct the filename\n",
        "    filename = f'cleaned_captions_{i}.csv'\n",
        "\n",
        "    # Check if the file exists\n",
        "    if os.path.exists(filename):\n",
        "        # Read the CSV file into a DataFrame and append to the list\n",
        "        df = pd.read_csv(filename)\n",
        "        all_captions_dfs.append(df)\n",
        "        print(f\"✅ Loaded {filename}\")\n",
        "    else:\n",
        "        print(f\"⚠️ File not found: {filename}, skipping.\")\n",
        "\n",
        "# Concatenate all DataFrames in the list\n",
        "if all_captions_dfs:\n",
        "    combined_captions_df = pd.concat(all_captions_dfs, ignore_index=True)\n",
        "\n",
        "    # Save the combined DataFrame to a new CSV file\n",
        "    combined_captions_df.to_csv('all_cleaned_captions.csv', index=False)\n",
        "    print(\"✅ Combined cleaned captions saved to 'all_cleaned_captions.csv'\")\n",
        "else:\n",
        "    print(\"⚠️ No cleaned caption files were found or loaded.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded cleaned_captions_1.csv\n",
            "✅ Loaded cleaned_captions_2.csv\n",
            "✅ Loaded cleaned_captions_3.csv\n",
            "✅ Loaded cleaned_captions_4.csv\n",
            "✅ Loaded cleaned_captions_5.csv\n",
            "✅ Loaded cleaned_captions_6.csv\n",
            "✅ Loaded cleaned_captions_7.csv\n",
            "✅ Combined cleaned captions saved to 'all_cleaned_captions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba36ff84"
      },
      "source": [
        "## Combine raw captions\n",
        "\n",
        "### Subtask:\n",
        "Read the raw caption text from the individual VTT files, extract the text, and save it as a single VTT file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3ddf47f",
        "outputId": "f7fbb3a3-2ad2-42af-ee5c-cdbe5f314c7c"
      },
      "source": [
        "# Initialize an empty string to store the combined raw caption text\n",
        "combined_raw_captions = \"\"\n",
        "\n",
        "# Iterate through the video numbers from 1 to 7\n",
        "for i in range(1, 8):\n",
        "    # Construct the raw caption filename\n",
        "    filename = f'captions_{i}.vtt'\n",
        "\n",
        "    # Check if the raw caption file exists\n",
        "    if os.path.exists(filename):\n",
        "        # Read the content of the current VTT file\n",
        "        with open(filename, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "        # Append the content to the combined raw caption storage\n",
        "        combined_raw_captions += content + \"\\n\" # Add a newline between files\n",
        "        print(f\"✅ Read raw captions from '{filename}'\")\n",
        "    else:\n",
        "        print(f\"⚠️ Raw caption file not found: '{filename}', skipping.\")\n",
        "\n",
        "# Write the combined raw caption text to a single output VTT file\n",
        "output_filename = 'all_raw_captions.vtt'\n",
        "with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "    f.write(combined_raw_captions)\n",
        "\n",
        "# Print a confirmation message\n",
        "print(f\"✅ Combined raw captions saved to '{output_filename}'\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Read raw captions from 'captions_1.vtt'\n",
            "✅ Read raw captions from 'captions_2.vtt'\n",
            "✅ Read raw captions from 'captions_3.vtt'\n",
            "✅ Read raw captions from 'captions_4.vtt'\n",
            "✅ Read raw captions from 'captions_5.vtt'\n",
            "✅ Read raw captions from 'captions_6.vtt'\n",
            "✅ Read raw captions from 'captions_7.vtt'\n",
            "✅ Combined raw captions saved to 'all_raw_captions.vtt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69bff65f"
      },
      "source": [
        "## Combine comments\n",
        "\n",
        "### Subtask:\n",
        "Read the cleaned comment data from the individual CSV files, combine them into a single DataFrame, and save it as a single CSV file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "991d4ffb",
        "outputId": "2fae4d07-e8a4-4ca1-8bb4-45686b69cb8e"
      },
      "source": [
        "# Initialize an empty list to store the DataFrames\n",
        "all_comments_dfs = []\n",
        "\n",
        "# Loop through the video numbers from 1 to 7\n",
        "for i in range(1, 8):\n",
        "    # Construct the filename for the cleaned comments CSV\n",
        "    filename = f'cleaned_comments_{i}.csv'\n",
        "\n",
        "    # Check if the file exists\n",
        "    if os.path.exists(filename):\n",
        "        # Read the CSV file into a pandas DataFrame and append to the list\n",
        "        try:\n",
        "            df = pd.read_csv(filename)\n",
        "            all_comments_dfs.append(df)\n",
        "            print(f\"✅ Loaded {filename}\")\n",
        "        except pd.errors.EmptyDataError:\n",
        "            print(f\"⚠️ File is empty: {filename}, skipping.\")\n",
        "        except FileNotFoundError:\n",
        "             print(f\"⚠️ File not found: {filename}, skipping.\") # Redundant due to os.path.exists, but kept for robustness\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading {filename}: {e}\")\n",
        "    else:\n",
        "        print(f\"⚠️ File not found: {filename}, skipping.\")\n",
        "\n",
        "\n",
        "# After the loop, check if the list of DataFrames is not empty\n",
        "if all_comments_dfs:\n",
        "    # Concatenate all DataFrames in the list into a single DataFrame\n",
        "    combined_comments_df = pd.concat(all_comments_dfs, ignore_index=True)\n",
        "\n",
        "    # Save the combined DataFrame to a new CSV file\n",
        "    output_filename = 'all_cleaned_comments.csv'\n",
        "    combined_comments_df.to_csv(output_filename, index=False)\n",
        "    print(f\"✅ Combined cleaned comments saved to '{output_filename}'\")\n",
        "else:\n",
        "    print(\"⚠️ No cleaned comment files were found or loaded.\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ File not found: cleaned_comments_1.csv, skipping.\n",
            "✅ Loaded cleaned_comments_2.csv\n",
            "✅ Loaded cleaned_comments_3.csv\n",
            "✅ Loaded cleaned_comments_4.csv\n",
            "✅ Loaded cleaned_comments_5.csv\n",
            "✅ Loaded cleaned_comments_6.csv\n",
            "✅ Loaded cleaned_comments_7.csv\n",
            "✅ Combined cleaned comments saved to 'all_cleaned_comments.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0f80bf9"
      },
      "source": [
        "## Combine raw comments (json)\n",
        "\n",
        "### Subtask:\n",
        "Read the raw comment data from the individual JSON files and combine them into a single JSON file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56c33e52",
        "outputId": "96aff000-1f57-4fcf-ea97-9e017867fd11"
      },
      "source": [
        "# Initialize an empty list to store the combined comment data\n",
        "all_raw_comments = []\n",
        "\n",
        "# Loop through the video numbers from 1 to 7\n",
        "for i in range(1, 8):\n",
        "    # Construct the filename for the raw comments JSON file\n",
        "    filename = f'comments_{i}.json'\n",
        "\n",
        "    # Check if the file exists\n",
        "    if os.path.exists(filename):\n",
        "        print(f\"Processing {filename}\")\n",
        "        # Open and read each line of the JSON file\n",
        "        with open(filename, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                # If the line is not empty, try to parse it as a JSON object\n",
        "                if line:\n",
        "                    try:\n",
        "                        comment = json.loads(line)\n",
        "                        # Append the parsed JSON object to the initialized list\n",
        "                        all_raw_comments.append(comment)\n",
        "                    except json.JSONDecodeError:\n",
        "                        # Handle potential JSONDecodeError\n",
        "                        print(f\"⚠️ Skipping invalid JSON line in {filename}: {line}\")\n",
        "    else:\n",
        "        print(f\"⚠️ File not found: {filename}, skipping.\")\n",
        "\n",
        "# After the loop, if the list of combined comment data is not empty\n",
        "if all_raw_comments:\n",
        "    # Write the entire list of dictionaries as a JSON array to a new output file\n",
        "    output_filename = 'all_raw_comments.json'\n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(all_raw_comments, f, indent=4) # Use indent=4 for readability\n",
        "\n",
        "    # Print a confirmation message\n",
        "    print(f\"✅ Combined raw comments saved to '{output_filename}'\")\n",
        "else:\n",
        "    # Print a message if no comment files were found or processed\n",
        "    print(\"⚠️ No raw comment files were found or processed.\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing comments_1.json\n",
            "Processing comments_2.json\n",
            "Processing comments_3.json\n",
            "Processing comments_4.json\n",
            "Processing comments_5.json\n",
            "Processing comments_6.json\n",
            "Processing comments_7.json\n",
            "✅ Combined raw comments saved to 'all_raw_comments.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e315173"
      },
      "source": [
        "## Combine raw comments (txt)\n",
        "\n",
        "### Subtask:\n",
        "Read the raw comment text from the individual JSON files and save the comment text into a single TXT file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cb3babb",
        "outputId": "7f611bba-d22b-4af4-9430-5c15d681e29a"
      },
      "source": [
        "# Initialize an empty list to store the raw comment text\n",
        "all_raw_comment_texts = []\n",
        "\n",
        "# Loop through the video numbers from 1 to 7\n",
        "for i in range(1, 8):\n",
        "    # Construct the filename for the raw comments JSON file for the current video number\n",
        "    filename = f'comments_{i}.json'\n",
        "\n",
        "    # Check if the file exists. If it doesn't, print a warning and continue to the next iteration.\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"⚠️ Raw comment file not found: '{filename}', skipping.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing raw comments from '{filename}'\")\n",
        "    # If the file exists, open and read each line of the JSON file.\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            # For each line, if it's not empty, try to parse it as a JSON object.\n",
        "            if line:\n",
        "                try:\n",
        "                    comment = json.loads(line)\n",
        "                    # If parsing is successful, extract the value associated with the 'text' key\n",
        "                    # from the parsed JSON object and append it to the list.\n",
        "                    # Handle potential KeyError if the 'text' key is not present.\n",
        "                    comment_text = comment.get('text')\n",
        "                    if comment_text:\n",
        "                        all_raw_comment_texts.append(comment_text)\n",
        "                except json.JSONDecodeError:\n",
        "                    # Handle potential json.JSONDecodeError if a line cannot be parsed\n",
        "                    # as a JSON object by printing a warning and skipping the line.\n",
        "                    print(f\"⚠️ Skipping invalid JSON line in {filename}: {line}\")\n",
        "                except KeyError:\n",
        "                    # Handle case where 'text' key is missing, though unlikely based on downloader\n",
        "                    print(f\"⚠️ Skipping line in {filename} with missing 'text' key: {line}\")\n",
        "\n",
        "# After the loop, check if the list of comment text is not empty.\n",
        "if all_raw_comment_texts:\n",
        "    # Join all the extracted comment texts with a newline character in between.\n",
        "    combined_text = \"\\n\".join(all_raw_comment_texts)\n",
        "\n",
        "    # Write the combined text to a new output file named 'all_raw_comments.txt' using UTF-8 encoding.\n",
        "    output_filename = 'all_raw_comments.txt'\n",
        "    with open(output_filename, 'w', encoding='utf-8') as out:\n",
        "        out.write(combined_text)\n",
        "\n",
        "    # Print a confirmation message indicating that the combined raw comments were saved to the output file.\n",
        "    print(f\"✅ Combined raw comment texts saved to '{output_filename}'\")\n",
        "else:\n",
        "    # If the list of comment text is empty, print a message indicating that no raw comment text was found or processed.\n",
        "    print(\"⚠️ No raw comment text found or processed from the input files.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing raw comments from 'comments_1.json'\n",
            "Processing raw comments from 'comments_2.json'\n",
            "Processing raw comments from 'comments_3.json'\n",
            "Processing raw comments from 'comments_4.json'\n",
            "Processing raw comments from 'comments_5.json'\n",
            "Processing raw comments from 'comments_6.json'\n",
            "Processing raw comments from 'comments_7.json'\n",
            "✅ Combined raw comment texts saved to 'all_raw_comments.txt'\n"
          ]
        }
      ]
    }
  ]
}